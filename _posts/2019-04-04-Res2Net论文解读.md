---
layout:     post              # 使用的布局（不需要改）
title:     Res2Net论文解读         # 标题
subtitle:   Res2Net #副标题
date:       2019-04-04       # 时间
author:     zhiwei        # 作者
header-img: img/post-bg-2015.jpg  #这篇文章标题背景图片
catalog: true             # 是否归档
tags:               #标签
    - 计算机视觉论文
---



论文：<https://arxiv.org/abs/1904.01169>

​	Abstract：在多个尺度上表示特征对于许多视觉任务非常重要。卷积神经网络（CNN） backbone 的最新进展不断展示出更强的多尺度表示能力，从而在广泛的应用中实现一致的性能提升。然而，大多数现有方法以分层方式（layer-wise）表示多尺度特征。在本文中，我们通过在一个单个残差块内构造分层的残差类连接，为CNN提出了一种新的构建模块，即Res2Net。Res2Net 以更细粒度（granular level）表示多尺度特征，并增加每个网络层的感受野（receptive fields）范围。所提出的Res2Net块可以融合到最先进的 backbone CNN模型中，例如ResNet，ResNeXt和DLA。我们在所有这些模型上评估 Res2Net 模块，并在广泛使用的数据集（例如CIFAR-100和ImageNet）上展示相对于基线模型的一致性能提升。关于代表性计算机视觉任务的进一步消融研究和实验结果，即目标检测，类激活 mapping 和显著目标检测，进一步验证了Res2Net相对于现有技术的基线方法的优越性。源码和训练模型将之后公开。

​	论文*Res2Net: A New Multi-scale Backbone Architecture*：在Resnet的bottleneck基础上，提出了参数量更少的bottleneck，如下图：

​      ![1](http://ws4.sinaimg.cn/large/007ccxpDgy1g1qvjragn5j30g50bnjru.jpg)           

​	图a为Resnet提出的标准网络，图b为本文提出。如图b所示，把$3 \times 3$的卷积分为s个group，${x_1},{x_2},{x_3},{x_4}$的大小与上面的$1 \times 1$的卷积一样，但是channel都为其的   。

  $\mathbf{y}_{i}=\left\{\begin{array}{ll}{\mathbf{x}_{i}} & {i=1} \\ {\mathbf{K}_{i}\left(\mathbf{x}_{i}+\mathbf{y}_{i-1}\right)} & {1<i \leqslant s}\end{array}\right.$  

​	输出   公式如上，可知在一个bottleneck内部又进行了类似外部的跳跃连接，最后${y_1},{y_2},{y_3},{y_4}$进行concat操作，使得channel保持不变。需要注意的是他split的第一个即${x_1}$是直接映射到${y_1}$的，作者说这有两层含义：①为了减少参数；②特征重利用。

​	作者在ResNet-50, ResNeXt-50 和 DLA-60 作为baseline进行实验。实验的框架使用的是pytorch，为公平实验作者复现了这三个网络，此外把其原始的bottleneck用本文提出的代替进行新的实验，并取得了好的结果。

