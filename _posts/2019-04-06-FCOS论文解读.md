---
layout:     post              # 使用的布局（不需要改）
title:      FCOS论文解读          # 标题
subtitle:   FCOS：Fully Convolutional One-Stage Object Detection #副标题
date:       2019-04-06      # 时间
author:     zhiwei        # 作者
header-img: img/post-bg-2015.jpg  #这篇文章标题背景图片
catalog: true             # 是否归档
tags:               #标签
    - 计算机视觉论文
---


论文：<https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1904.01355>

&emsp;&emsp;Abstract：我们提出了一种全卷积的 one-stage 目标检测器（FCOS），以每像素预测方式解决目标检测，类似于语义分割。几乎所有最先进的目标检测器，如RetinaNet，SSD，YOLOv3和Faster R-CNN都依赖于预定义的锚框（anchor boxes）。相比之下，我们提出的检测器FCOS不需要锚框，即 proposal free。通过消除预定义的锚框，FCOS完全避免了与锚框相关的复杂计算，例如在训练期间计算重叠并且显著减少了训练内存。更重要的是，我们还避免了与锚框相关的所有超参数，这些参数通常对最终检测性能非常敏感。凭借唯一的后处理：非极大值抑制（NMS），我们的检测器FCOS优于以前基于锚框的one-stage探测器，具有更简单的优势。我们首次展示了一种更加简单灵活的检测框架，可以提高检测精度。我们希望提出的FCOS框架可以作为许多其他实例级任务的简单而强大的替代方案。

![QQ截图20190406165005](http://ws1.sinaimg.cn/large/007ccxpDgy1g1t0i2wi8xj30a409bdko.jpg)

&emsp;&emsp;FCOS的网络框图：**【Backbone】 + 【特征金字塔（Feature Pyramid）】+ 【Classification + Center-ness + Regression】**。这里的 **Center-ness** 是本论文的创新之一。**另外敲重点，本文之所以独树一帜，是因为其 anchor-box free的思路**

![1](http://ws3.sinaimg.cn/large/007ccxpDgy1g1t0jv7p26j30l80bomzd.jpg)

LOSS:

![2](http://wx1.sinaimg.cn/large/007ccxpDgy1g1t0kz1wcgj30j404zgm1.jpg)

Regression:

![1](http://wx1.sinaimg.cn/large/007ccxpDgy1g1t0lyxqdrj30ao02u74b.jpg)

centerness^*^ :

![2](http://wx1.sinaimg.cn/large/007ccxpDgy1g1t0nsm8bbj30fw02q3yp.jpg)